{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Clump</th>\n",
       "      <th>UniCell_Size</th>\n",
       "      <th>Uni_CellShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SEpith</th>\n",
       "      <th>BareN</th>\n",
       "      <th>BChromatin</th>\n",
       "      <th>NoemN</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61634</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63375</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76389</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95719</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code  Clump  UniCell_Size  Uni_CellShape  MargAdh  SEpith  BareN  \\\n",
       "0   61634      5             4              3        1       2      2   \n",
       "1   63375      9             1              2        6       4     10   \n",
       "2   76389     10             4              7        2       2      8   \n",
       "3   95719      6            10             10       10       8     10   \n",
       "4  128059      1             1              1        1       2      5   \n",
       "\n",
       "   BChromatin  NoemN  Mitoses      Class  \n",
       "0           2      3        1     Benign  \n",
       "1           7      7        2  Malignant  \n",
       "2           6      1        1  Malignant  \n",
       "3           7     10        7  Malignant  \n",
       "4           5      1        1     Benign  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Cases/Wisconsin/BreastCancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code             0\n",
       "Clump            0\n",
       "UniCell_Size     0\n",
       "Uni_CellShape    0\n",
       "MargAdh          0\n",
       "SEpith           0\n",
       "BareN            0\n",
       "BChromatin       0\n",
       "NoemN            0\n",
       "Mitoses          0\n",
       "Class            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump</th>\n",
       "      <th>UniCell_Size</th>\n",
       "      <th>Uni_CellShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SEpith</th>\n",
       "      <th>BareN</th>\n",
       "      <th>BChromatin</th>\n",
       "      <th>NoemN</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump  UniCell_Size  Uni_CellShape  MargAdh  SEpith  BareN  BChromatin  \\\n",
       "0        5             4              3        1       2      2           2   \n",
       "1        9             1              2        6       4     10           7   \n",
       "2       10             4              7        2       2      8           6   \n",
       "3        6            10             10       10       8     10           7   \n",
       "4        1             1              1        1       2      5           5   \n",
       "..     ...           ...            ...      ...     ...    ...         ...   \n",
       "694     10            10             10       10       5     10          10   \n",
       "695      5            10             10       10       4     10           5   \n",
       "696      5             1              1        1       2      1           3   \n",
       "697      4             1              1        1       1      1           2   \n",
       "698      1             1              3        1       2      1           2   \n",
       "\n",
       "     NoemN  Mitoses  \n",
       "0        3        1  \n",
       "1        7        2  \n",
       "2        1        1  \n",
       "3       10        7  \n",
       "4        1        1  \n",
       "..     ...      ...  \n",
       "694     10        7  \n",
       "695      6        3  \n",
       "696      2        1  \n",
       "697      1        1  \n",
       "698      1        1  \n",
       "\n",
       "[699 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 1:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Benign\n",
       "1      Malignant\n",
       "2      Malignant\n",
       "3      Malignant\n",
       "4         Benign\n",
       "         ...    \n",
       "694    Malignant\n",
       "695    Malignant\n",
       "696       Benign\n",
       "697       Benign\n",
       "698       Benign\n",
       "Name: Class, Length: 699, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mx = MinMaxScaler()\n",
    "X_train = mx.fit_transform(X_train)\n",
    "X_test = mx.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lor = LogisticRegression(solver='liblinear')\n",
    "lor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9828571428571429"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9613977389516958"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lor = LogisticRegression()\n",
    "\n",
    "results = cross_val_score(lor, X, y, cv=kfold)  # scoring='acc_score' by default\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10048237864728342"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_val_score(lor, X, y, scoring='neg_log_loss', cv=kfold)\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lor = LogisticRegression(max_iter=200)\n",
    "params = {'penalty':['l1','l2','elasticnet',None],\n",
    "          'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "          'l1_ratio': np.arange(0,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.9642651593011304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "                                                ^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.96426516        nan        nan        nan 0.96426516\n",
      " 0.96139774 0.96426516 0.96139774 0.96139774 0.96283659 0.96426516\n",
      "        nan        nan        nan        nan        nan 0.96426516\n",
      " 0.95996917        nan 0.95996917 0.95996917 0.96283659 0.96426516]\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Default scoring=acc score\n",
    "gcv = GridSearchCV(lor, param_grid=params,\n",
    "                   cv=kfold)\n",
    "gcv.fit(X, y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "-0.09891661103452001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "                                                ^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [        nan -0.09891661         nan         nan         nan -0.1052679\n",
      " -0.10048238 -0.11188119 -0.10048196 -0.10047085 -0.10067813 -0.10607289\n",
      "         nan         nan         nan         nan         nan -0.10607954\n",
      " -0.10211821         nan -0.1021189  -0.10210115 -0.10143017 -0.10656444]\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# log loss\n",
    "gcv = GridSearchCV(lor, param_grid=params,\n",
    "                   cv=kfold, scoring='neg_log_loss')\n",
    "gcv.fit(X, y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45374294 0.05388446 0.30702376 0.19684591 0.03002977 0.39160169\n",
      "  0.34224516 0.14109174 0.38310345]]\n",
      "{'l1_ratio': 0, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "best_model = gcv.best_estimator_\n",
    "print(best_model.coef_)\n",
    "print(gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(l1_ratio=0, max_iter=200, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(l1_ratio=0, max_iter=200, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(l1_ratio=0, max_iter=200, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972463768115941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "plt.xlabel(\"1-Specificity\")\n",
    "plt.show()\n",
    "\n",
    "### AUC\n",
    "print(roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.73247682e-04, 9.99726752e-01],\n",
       "       [8.68336682e-01, 1.31663318e-01],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [1.91488308e-04, 9.99808512e-01],\n",
       "       [9.89515762e-01, 1.04842376e-02],\n",
       "       [9.95516759e-01, 4.48324077e-03],\n",
       "       [8.18664808e-03, 9.91813352e-01],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [1.87134854e-03, 9.98128651e-01],\n",
       "       [9.71530553e-01, 2.84694471e-02],\n",
       "       [8.77120835e-01, 1.22879165e-01],\n",
       "       [9.63172341e-01, 3.68276588e-02],\n",
       "       [4.19302998e-03, 9.95806970e-01],\n",
       "       [9.49830555e-01, 5.01694446e-02],\n",
       "       [9.89515762e-01, 1.04842376e-02],\n",
       "       [9.89515762e-01, 1.04842376e-02],\n",
       "       [1.77239114e-03, 9.98227609e-01],\n",
       "       [3.76844136e-02, 9.62315586e-01],\n",
       "       [9.85043165e-01, 1.49568347e-02],\n",
       "       [9.08758379e-01, 9.12416205e-02],\n",
       "       [9.54590373e-01, 4.54096266e-02],\n",
       "       [9.95516759e-01, 4.48324077e-03],\n",
       "       [5.24629490e-03, 9.94753705e-01],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [9.61796032e-01, 3.82039684e-02],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [2.38577478e-03, 9.97614225e-01],\n",
       "       [1.33106281e-01, 8.66893719e-01],\n",
       "       [6.30406601e-04, 9.99369593e-01],\n",
       "       [2.04182067e-02, 9.79581793e-01],\n",
       "       [1.88896289e-02, 9.81110371e-01],\n",
       "       [2.25993698e-02, 9.77400630e-01],\n",
       "       [9.76727247e-01, 2.32727533e-02],\n",
       "       [9.63122639e-01, 3.68773613e-02],\n",
       "       [6.92836401e-01, 3.07163599e-01],\n",
       "       [9.48239462e-01, 5.17605380e-02],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [6.85156620e-03, 9.93148434e-01],\n",
       "       [9.90687257e-01, 9.31274260e-03],\n",
       "       [9.48051577e-01, 5.19484232e-02],\n",
       "       [3.26683532e-01, 6.73316468e-01],\n",
       "       [1.52074296e-04, 9.99847926e-01],\n",
       "       [6.99940709e-04, 9.99300059e-01],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [6.18693253e-02, 9.38130675e-01],\n",
       "       [6.11919427e-02, 9.38808057e-01],\n",
       "       [9.52238202e-01, 4.77617983e-02],\n",
       "       [6.19184641e-03, 9.93808154e-01],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [9.61365414e-01, 3.86345863e-02],\n",
       "       [9.85574639e-01, 1.44253614e-02],\n",
       "       [9.95516759e-01, 4.48324077e-03],\n",
       "       [9.65508569e-01, 3.44914311e-02],\n",
       "       [9.69919756e-01, 3.00802445e-02],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [9.73827824e-01, 2.61721762e-02],\n",
       "       [1.51667959e-02, 9.84833204e-01],\n",
       "       [9.89501225e-01, 1.04987746e-02],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [9.93579372e-01, 6.42062810e-03],\n",
       "       [1.33021642e-01, 8.66978358e-01],\n",
       "       [9.84008170e-01, 1.59918300e-02],\n",
       "       [9.80181681e-01, 1.98183190e-02],\n",
       "       [2.87687196e-03, 9.97123128e-01],\n",
       "       [9.92044006e-01, 7.95599374e-03],\n",
       "       [9.70013060e-01, 2.99869399e-02],\n",
       "       [2.67622041e-02, 9.73237796e-01],\n",
       "       [9.69919756e-01, 3.00802445e-02],\n",
       "       [9.48051577e-01, 5.19484232e-02],\n",
       "       [9.86522882e-01, 1.34771183e-02],\n",
       "       [9.91598396e-01, 8.40160446e-03],\n",
       "       [9.75678436e-01, 2.43215636e-02],\n",
       "       [9.41539183e-01, 5.84608166e-02],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [9.54590373e-01, 4.54096266e-02],\n",
       "       [9.92378951e-01, 7.62104868e-03],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [2.06352078e-03, 9.97936479e-01],\n",
       "       [1.08218624e-02, 9.89178138e-01],\n",
       "       [9.71516041e-01, 2.84839591e-02],\n",
       "       [7.22410848e-02, 9.27758915e-01],\n",
       "       [9.94637793e-01, 5.36220722e-03],\n",
       "       [8.94619289e-01, 1.05380711e-01],\n",
       "       [9.85574639e-01, 1.44253614e-02],\n",
       "       [9.46339911e-01, 5.36600888e-02],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [9.85574639e-01, 1.44253614e-02],\n",
       "       [9.91695640e-01, 8.30435998e-03],\n",
       "       [9.86397901e-03, 9.90136021e-01],\n",
       "       [9.90547921e-01, 9.45207917e-03],\n",
       "       [1.99853919e-02, 9.80014608e-01],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [8.82588158e-02, 9.11741184e-01],\n",
       "       [2.19337225e-02, 9.78066278e-01],\n",
       "       [9.65508569e-01, 3.44914311e-02],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [6.58765002e-01, 3.41234998e-01],\n",
       "       [9.38708175e-01, 6.12918247e-02],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [7.12466642e-03, 9.92875334e-01],\n",
       "       [9.80181681e-01, 1.98183190e-02],\n",
       "       [3.21726366e-05, 9.99967827e-01],\n",
       "       [9.41509738e-01, 5.84902619e-02],\n",
       "       [1.06901720e-02, 9.89309828e-01],\n",
       "       [9.93492181e-01, 6.50781927e-03],\n",
       "       [8.66757872e-03, 9.91332421e-01],\n",
       "       [3.26526234e-02, 9.67347377e-01],\n",
       "       [9.57601616e-04, 9.99042398e-01],\n",
       "       [9.93139762e-01, 6.86023798e-03],\n",
       "       [9.61365414e-01, 3.86345863e-02],\n",
       "       [2.26643400e-02, 9.77335660e-01],\n",
       "       [9.90547921e-01, 9.45207917e-03],\n",
       "       [9.69919756e-01, 3.00802445e-02],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [9.87475067e-01, 1.25249333e-02],\n",
       "       [2.34371451e-02, 9.76562855e-01],\n",
       "       [9.91506355e-01, 8.49364484e-03],\n",
       "       [9.78042631e-01, 2.19573687e-02],\n",
       "       [8.59831741e-01, 1.40168259e-01],\n",
       "       [1.77097259e-01, 8.22902741e-01],\n",
       "       [9.13365741e-01, 8.66342588e-02],\n",
       "       [2.04823668e-02, 9.79517633e-01],\n",
       "       [9.78042631e-01, 2.19573687e-02],\n",
       "       [9.90547921e-01, 9.45207917e-03],\n",
       "       [9.89501225e-01, 1.04987746e-02],\n",
       "       [9.95516759e-01, 4.48324077e-03],\n",
       "       [1.58011112e-03, 9.98419889e-01],\n",
       "       [1.96049279e-03, 9.98039507e-01],\n",
       "       [8.33502566e-04, 9.99166497e-01],\n",
       "       [3.18315076e-02, 9.68168492e-01],\n",
       "       [9.73837629e-01, 2.61623710e-02],\n",
       "       [9.93817372e-01, 6.18262805e-03],\n",
       "       [1.30681089e-03, 9.98693189e-01],\n",
       "       [9.89515762e-01, 1.04842376e-02],\n",
       "       [9.92377871e-01, 7.62212906e-03],\n",
       "       [9.80181681e-01, 1.98183190e-02],\n",
       "       [3.36639952e-03, 9.96633600e-01],\n",
       "       [8.97514648e-01, 1.02485352e-01],\n",
       "       [9.89515762e-01, 1.04842376e-02],\n",
       "       [9.65066639e-01, 3.49333610e-02],\n",
       "       [9.25850153e-01, 7.41498467e-02],\n",
       "       [9.02546036e-01, 9.74539643e-02],\n",
       "       [1.12937347e-02, 9.88706265e-01],\n",
       "       [9.46284834e-01, 5.37151657e-02],\n",
       "       [1.51558730e-02, 9.84844127e-01],\n",
       "       [2.22781810e-01, 7.77218190e-01],\n",
       "       [2.45061665e-02, 9.75493833e-01],\n",
       "       [9.31996614e-01, 6.80033862e-02],\n",
       "       [1.30079176e-03, 9.98699208e-01],\n",
       "       [9.80181681e-01, 1.98183190e-02],\n",
       "       [9.95516759e-01, 4.48324077e-03],\n",
       "       [1.99272149e-04, 9.99800728e-01],\n",
       "       [6.48999845e-02, 9.35100016e-01],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [9.59927608e-01, 4.00723919e-02],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [1.93830722e-02, 9.80616928e-01],\n",
       "       [3.28683824e-01, 6.71316176e-01],\n",
       "       [9.79217092e-01, 2.07829080e-02],\n",
       "       [9.95516759e-01, 4.48324077e-03],\n",
       "       [9.04750770e-01, 9.52492298e-02],\n",
       "       [6.45425384e-01, 3.54574616e-01],\n",
       "       [9.93139762e-01, 6.86023798e-03],\n",
       "       [9.84008170e-01, 1.59918300e-02],\n",
       "       [9.78042631e-01, 2.19573687e-02],\n",
       "       [9.84008170e-01, 1.59918300e-02],\n",
       "       [5.11670372e-02, 9.48832963e-01],\n",
       "       [9.86989694e-01, 1.30103064e-02],\n",
       "       [9.91479340e-01, 8.52066033e-03],\n",
       "       [9.80889898e-01, 1.91101022e-02],\n",
       "       [1.20944267e-03, 9.98790557e-01],\n",
       "       [9.84008170e-01, 1.59918300e-02],\n",
       "       [9.69919756e-01, 3.00802445e-02],\n",
       "       [3.34604262e-02, 9.66539574e-01],\n",
       "       [7.43494272e-03, 9.92565057e-01]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
